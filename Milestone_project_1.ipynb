{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone Project 1: Food Vision Big\n",
    "\n",
    "See the annoted version of this notebook on GitHub: https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/07_food_vision_milestone_project_1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check GPU\n",
    "\n",
    "Using mixed precision training we need a GPU with score 7.0+ (see here: https://developer.nvidia.com/cuda-gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get helper functions \n",
    "\n",
    "In past modules, we've created a bunch of different helper functions to do small tasks required for our notebooks.\n",
    "\n",
    "Rather than rewrite all of these, we can import a script and load them in from there.\n",
    "\n",
    "The script we've got avialable can be found on GitHub: https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/helper_functions.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download helper_function script\n",
    "# !wget -P ./Extras/ https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/refs/heads/main/extras/helper_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import series of helper functions for the notebook\n",
    "from Extras.helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Tensorflow Datasets to download data\n",
    "\n",
    "If you want to get an overview of TensorFlow Datasets (tfds), read the guide: https://www.tensorflow.org/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get TensorFlow Datasets\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# List all available datasets\n",
    "datasets_list = tfds.list_builders() # get all available datasets in TFDS\n",
    "print(\"food101\" in datasets_list) # is our target dataset available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n"
     ]
    }
   ],
   "source": [
    "# Load in the data\n",
    "(train_data, test_data), ds_info = tfds.load(name = \"food101\",\n",
    "                                             split = [\"train[:75%]\", \"train[25%:]\"],\n",
    "                                             shuffle_files = True,\n",
    "                                             as_supervised = True, # Datasets gets returned in tuple format\n",
    "                                             with_info = True,\n",
    "                                             data_dir = \"./Data\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='food101',\n",
       "    version=1.0.0,\n",
       "    description='This dataset consists of 101 food categories, with 101'000 images. For each class, 250 manually reviewed test images are provided as well as 750 training images. On purpose, the training images were not cleaned, and thus still contain some amount of noise. This comes mostly in the form of intense colors and sometimes wrong labels. All images were rescaled to have a maximum side length of 512 pixels.',\n",
       "    urls=['http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz'],\n",
       "    features=FeaturesDict({\n",
       "        'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=101),\n",
       "    }),\n",
       "    total_num_examples=101000,\n",
       "    splits={\n",
       "        'train': 101000,\n",
       "    },\n",
       "    supervised_keys=('image', 'label'),\n",
       "    citation=\"\"\"@inproceedings{bossard14,\n",
       "      title = {Food-101 -- Mining Discriminative Components with Random Forests},\n",
       "      author = {Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},\n",
       "      booktitle = {European Conference on Computer Vision},\n",
       "      year = {2014}\n",
       "    }\"\"\",\n",
       "    redistribution_info=,\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeaturesDict({\n",
       "    'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
       "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=101),\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features of Food101 from tfds\n",
    "ds_info.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple_pie',\n",
       " 'baby_back_ribs',\n",
       " 'baklava',\n",
       " 'beef_carpaccio',\n",
       " 'beef_tartare',\n",
       " 'beet_salad',\n",
       " 'beignets',\n",
       " 'bibimbap',\n",
       " 'bread_pudding',\n",
       " 'breakfast_burrito']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the class names \n",
    "class_names = ds_info.features[\"label\"].names\n",
    "class_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Food101 data from Tensorflow Dataset\n",
    "\n",
    "To become one with data, we want to find:\n",
    "\n",
    "* class names\n",
    "* The shape of our input tensor (image tensor)\n",
    "* The datatype of our input data\n",
    "* What the labels look like (e.g are they one-hot-encoded or are they label encoded)\n",
    "* Do the labels match up with the class names ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take one sample of training data\n",
    "train_one_sample = train_data.take(1) # samples are in the format (image_tensor, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=(TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does one sample of our data look like ?\n",
    "train_one_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
